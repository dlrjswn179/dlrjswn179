{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "처음 배우는 딥러닝 챗봇.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "GK4ZZVvinsLF",
        "ABeYIEvSosXz",
        "WST8c8kYDhSG"
      ],
      "authorship_tag": "ABX9TyPA/Cu3i7aKJuOB8RG7bgYQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dlrjswn179/dlrjswn179/blob/main/%EC%B2%98%EC%9D%8C_%EB%B0%B0%EC%9A%B0%EB%8A%94_%EB%94%A5%EB%9F%AC%EB%8B%9D_%EC%B1%97%EB%B4%87.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "우울증 관련 챗봇 순서 (미정)\n",
        "\n",
        "1. 데이터셋 선별/ 분류 \n",
        "2. 토크나이징\n",
        "3. 임베딩(텍스트 유사도): 공부한 Word2VEC 예정\n",
        "4. 모델: 현재까지 성능이 제일 좋아보이는 KoELECTRA 예정, 감성분류용, 대화용 두개.\n",
        "   - KoELECTRA로 텍스트까지 뽑아낼 수 있는 방법 공부 필요!!!!!\n",
        "   - 감성분류용 KoELECTRA. 감성은 몇개로 분류할 건지도?!!!!!\n",
        "   - 파이프라인도 가능하지만, 아직 난이도가 안되니 koELECTRA로만 실행해보는 걸로!!!!\n",
        "\n",
        "5. 우울증일시 모델: koELECTRA? 진단용(대화용), 분류용!!! \n",
        "6. 분류 후는 무엇을 해야하는지? 고민!"
      ],
      "metadata": {
        "id": "Pf4iqVcfTCo0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CHAPTER 1 챗봇 입문하기\n"
      ],
      "metadata": {
        "id": "GK4ZZVvinsLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#챗봇은 채터와 로봇의 합성어로, 대화하는 로봇이라고 정의할 수 있습니다."
      ],
      "metadata": {
        "id": "P57pJJxZn0ox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#범용 챗봇 개발은 기술적 어려움이 많은 분야입니다. 따라서 챗봇 개발 전에 어떤 분야에서 어떤 목적으로 사용할 챗봇인지 명확하게 정의해야 합니다."
      ],
      "metadata": {
        "id": "zdJ7BuNdpNJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#국내에서는 의료, 상담, 금융, 쇼핑, 마케팅 등 많은 분야에서 챗봇을 사용하고 있으며 챗봇 사용 비중이 점차 늘어나고 있는 추세입니다.\n",
        "#카카오 챗봇 사례, 대학병원 챗봇 사례, 제약회사 챗봇 사례"
      ],
      "metadata": {
        "id": "jKQInRs6pPlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CHAPTER 2 파이썬 시작하기"
      ],
      "metadata": {
        "id": "ABeYIEvSosXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#파이썬은 전 세계적으로 가장 많이 사용하고 있는 언어 Top 3에 랭크될 만큼 넓은 사용자 층을 보유하고 있는 언어입니다.\n",
        "#파이썬 3은 2 버전과는 다르게 모든 변수를 객체로 처리하며, 모든 문자열을 유니코드인 str 객체로 통일했습니다. 그 외에도 내부적으로 많은 변화가 있습니다. 이 책에서는 3 버전을 사용할 것입니다."
      ],
      "metadata": {
        "id": "qikhArMwov-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#일반적으로 프로그램 내부 코드는 동작 행위와 데이터 상태로 구분되어 있습니다."
      ],
      "metadata": {
        "id": "06hetZ_ipXBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#자료형이란 프로그램 내부에서 사용하는 데이터의 형태를 의미합니다.\n",
        "#프로그램 개발 시 필요한 데이터를 어떤 자료형 변수에 보관할 것인지 알아야 하기 때문에 자료형은 매우 기본적이면서도 중요한 내용입니다."
      ],
      "metadata": {
        "id": "ZgGXwUBdpY2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#숫자\n",
        "\n",
        "#정수계산 #소수점을 사용하지 않는 한 기본적으로 int형으로 처리.\n",
        "10 + 5\n",
        "\n",
        "#실수계산 #소수점을 사용하거나 계산 결과가 실수인 경우에는 float형으로 처리. #나눗셈(/) 연산의 결과는 항상 float형. #나눗셈 결과를 정수 형태로 얻기 위해서는 // 연산자를 사용해야 하며, 나머지를 계산하기 위해서는 % 연산자를 사용해야 함.\n",
        "2.2 * 5\n",
        "3 / 2\n",
        "3 // 2 \n",
        "3 % 2\n",
        "\n",
        "#거듭제곱 계산\n",
        "2 ** 5\n",
        "\n",
        "#변수 사용\n",
        "a = 10\n",
        "b = 20\n",
        "a * b\n"
      ],
      "metadata": {
        "id": "oOFN5lPKp4Ot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#문자열\n",
        "\n",
        "#문자열 사용\n",
        "'1234'\n",
        "\n",
        "#문자열 변수 사용(1)\n",
        "msg = 'Hello'\n",
        "error = \"err 404\"\n",
        "\n",
        "#문자열 변수 사용(2)\n",
        "msg1 = '\"Nice to meet you\", chatbot says'\n",
        "msg2 = \"I'm programming now\"\n",
        "\n",
        "#멀티라인 문자열(1) #간단한 문장인 경우에는 이스케이프 코드 \\n을 사용함.\n",
        "msg3 = 'Hello\\nbro!!'\n",
        "\n",
        "#멀티라인 문자열(2) #복잡한 문장인 경우에는 작은따옴표 3개 또는 큰따옴표 3개를 연속적으로 사용함.\n",
        "msg4 = '''Hello\n",
        "bro!!'''\n",
        "\n",
        "#멀티라인 문자열(3) \n",
        "msg4 = \"\"\"Hello\n",
        "bro!!\"\"\"\n",
        "\n",
        "#이스케이프 코드 #이스케이프 코드란 프로그래밍할 때 사용할 수 있도록 시스템에 미리 정의해놓은 코드. 주로 출력 메시지를 정렬하거나 기호를 출력하는 데 사용함.\n",
        "#\\n(줄바꿈), \\t(탭), \\\\(문자\\출력), \\'(문자'출력), \\\"(문자\"출력)\n"
      ],
      "metadata": {
        "id": "UWfCUqEfG0n2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#리스트\n",
        "\n",
        "#리스트 정의 #대괄호[]를 사용하며, 데이터 요소들을 쉼표(,)로 구분. #숫자 및 문자열뿐만 아니라 객체 형태의 데이터도 추가할 수 있음.\n",
        "numbers = [1,2,3,4,5]\n",
        "real_numbers = [1.0, 2.0, 3.0, 4, 5]\n",
        "\n",
        "#리스트 인덱싱 및 슬라이싱 #인덱싱은 리스트에 접근하려면 대괄호를 사용하며, 첫 번째 요소는 0부터 시작함. #슬라이싱은 시작 위치와 끝 위치, 쌍점(:)을 사용해 새로운 리스트 생성함. 원본 리스트를 훼손하지 않음.\n",
        "numbers[0]\n",
        "numbers[-1]\n",
        "numbers[2:]\n",
        "numbers[-2:]\n",
        "numbers[1:-2]\n",
        "\n",
        "#리스트 요소 수정\n",
        "numbers[0] = 9\n",
        "\n",
        "#리스트 요소 추가 #변수.append(): 리스트의 마지막에 요소를 추가하는 함수\n",
        "numbers.append(9)\n",
        "\n",
        "#리스트 요소 삽입 #변수.insert(): 원하는 위치에 데이터를 삽입하는 함수\n",
        "numbers.insert(1,1.5)\n",
        "\n",
        "#리스트 요소 꺼내고 삭제(1) #변수.pop(): 리스트의 맨 마지막 요소나 원하는 위치의 요소를 꺼내면서 삭제하는 함수\n",
        "numbers.pop()\n",
        "\n",
        "#리스트 요소 꺼내고 삭제(2)\n",
        "numbers.pop(2)\n",
        "a = numbers.pop(3)\n",
        "\n",
        "#del 키워드로 리스트 요소 삭제 #del 리스트요소: 요소를 꺼내지 않고 바로 삭제하는 키워드\n",
        "del numbers[2]\n",
        "\n",
        "#리스트 요소 개수 구하기 #len(변수)\n",
        "len(numbers)\n"
      ],
      "metadata": {
        "id": "cYf0zU17Ksci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#튜플\n",
        "\n",
        "#튜플 정의 #소괄호()를 사용함\n",
        "numbers = (1, 2, 3, 4, 5)\n",
        "numbers = (1.0, 2.0, 3.0, 4, 5, 'six')\n",
        "\n",
        "#튜플 인덱싱 및 슬라이싱 #인덱싱은 리스트와 마찬가지로 대괄호를 사용함. #슬라이싱은 기존 튜플에서 잘라낼 시작위치와 끝 위치, 쌍점을 사용해 새로운 튜플을 생성함. #요소를 변경하지 못하는 점만 빼면 리스트와 동일함.\n",
        "numbers[1]\n",
        "numbers[-1]\n",
        "numbers[2:]\n",
        "numbers[-2:]\n",
        "numbers[1:-2]\n",
        "\n",
        "#튜플 요소 수정 #튜플의 요소는 수정할 수 없음. 오류를 출력함.\n",
        "numbers[0] = 9 #오류를 출력함.\n",
        "\n",
        "#튜플 덧셈 연산(1) #덧셈 연산을 이용해서 데이터를 추가한듯한 효과를 만들 수는 있음. #튜플 객체끼리만 가능함.\n",
        "new_numbers = numbers + (6,7)\n",
        "\n",
        "#튜플 덧셈 연산(2) #int형 숫자 1을 기존 튜플과 덧셈 연산을 했을 땐 오류를 출력함. #소괄호 내에 있는 데이터가 튜플 요소임을 쉼표로 알려주어야 함.\n",
        "numbers + (1) #오류를 출력함\n",
        "\n",
        "#튜플 덧셈 연산(3) \n",
        "numbers + (1,)\n"
      ],
      "metadata": {
        "id": "3duew3lGNN3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#딕셔너리\n",
        "\n",
        "#딕셔너리 기본 #중괄호{}를 사용함. #key와 value를 한 쌍으로 가지는 해시 형태의 자료형. #key에는 숫자와 문자열만 사용가능하며, value에는 데이터의 형태제한이 없음. #key는 한 번 정의되면 변경 불가능하지만, value는 변경 가능.\n",
        "user1 = {'name' : '홍길동', 'age' : 30, 'email' : 'hong@hanbit.co.kr'}\n",
        "\n",
        "#딕셔너리의 키가 문자열\n",
        "dict1 = {'Kei' : [100, 'hi', 4.5]}\n",
        "dict1['Kei'][1]\n",
        "\n",
        "#딕셔너리의 키가 숫자 #딕셔너리는 순서 없는 자료형이기 때문에 인덱스로 value에 접근할 수 없음. 딕셔너리의 key가 숫자인 경우에는 인덱스처럼 보이기 때문에 헷갈리지 않게 주의해야함.\n",
        "dict2 = {10 : 'ten'}\n",
        "dict2[10]\n",
        "\n",
        "#딕셔너리 데이터 쌍 추가(1) #대괄호를 이용해 원하는 key와 value를 저장함.\n",
        "dict3 = {}\n",
        "dict3['a'] = 'A'\n",
        "dict3['b'] = 'B'\n",
        "\n",
        "#딕셔너리 데이터 쌍 추가(2) #value에도 다양한 형태의 자료형을 추가할 수 있음.\n",
        "dict3[3] = [1,2,3]\n",
        "dict3[4] = {'name' : 'Kei', 'age' : 35}\n",
        "\n",
        "#딕셔너리 데이터 쌍 삭제 #특정 key를 가지는 데이터 쌍을 삭제하기 위해서는 del 키워드를 사용함. #모든 데이터 쌍을 한 번에 삭제하기 위해서는 clear() 함수를 사용함.\n",
        "del dict3['a']\n",
        "dict3.clear()\n"
      ],
      "metadata": {
        "id": "i5p8L4_oO59A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#불리언\n",
        "\n",
        "#불리언 자료형 사용 #불리언은 참과 거짓을 나타내는 자료형으로, 해당 조건이 참인지 거짓인지 논리적으로 판별하는데 사용함. #첫 문자는 항상 대문자를 사용해야 함.\n",
        "check = True\n",
        "uncheck = False\n",
        "type(check)\n",
        "uncheck\n"
      ],
      "metadata": {
        "id": "aq6uP06mQ-iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#if 조건문\n",
        "\n",
        "#if 제어문 사용(1) #if 조건문은 해당 조건을 판단했을 때 논리적으로 참인 경우에만 조건문에 포함되어 있는 코드를 수행함.\n",
        "check = True\n",
        "if check:\n",
        "  print('-' * 13)\n",
        "  print('check is true')\n",
        "  print('-' * 13) #곱셈 연산을 이용해서 동일한 문자를 n번 출력할 수 있음.\n",
        "\n",
        "#if 제어문 사용(2)\n",
        "check = False\n",
        "if not check:\n",
        "  print('-' * 14)\n",
        "  print('check is false')\n",
        "  print('-' * 14)\n",
        "\n",
        "#if 제어문 사용(3) #검사할 때 == 혹은 !=을 이용할 수 있음.\n",
        "check = False\n",
        "if check == False:\n",
        "  print('-' * 14)\n",
        "  print('check is false')\n",
        "  print('-' * 14)\n",
        "if check != True:\n",
        "  print('-' * 14)\n",
        "  print('check is false')\n",
        "  print('-' * 14)\n",
        "\n",
        "#조건문에 사용하는 연산자\n",
        "#==, !=, and, or, not, >, >=, <, <=, 그리고 그냥 A만 적는 것.\n",
        "\n",
        "#if 제어문 사용(4)\n",
        "age = 15\n",
        "if age >= 19:\n",
        "  print('You are an adult')\n",
        "else:\n",
        "  print('You are not an adult')  \n",
        "score = 84\n",
        "if score >= 90:\n",
        "  print('Grade A')\n",
        "elif score >= 80:\n",
        "  print('Grade B')\n",
        "elif score >= 70:\n",
        "  print('Grade C')\n",
        "else:\n",
        "  print('Grade D')\n"
      ],
      "metadata": {
        "id": "fVpAVqEVT0uK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#while 반복문 \n",
        "\n",
        "#while 반복문 사용(1) #while 반복문은 해당 조건이 거짓이 될 때까지 반복해서 코드를 수행합니다. 조건이 False가 되면 무한루프에 빠졌다고 표현함. Ctrl+C.\n",
        "i=1\n",
        "while i <= 10:\n",
        "  print('i=%d' %i) #문자열 포매팅\n",
        "  i = i + 1\n",
        "\n",
        "#문자열 포매팅 종류\n",
        "#%d(10진수 출력), %x(16진수 출력), %o(8진수 출력), %f(실수 출력), %s(문자열 출력)\n",
        "\n",
        "#while 반복문 사용(2) #input() 함수를 통해 입력되는 키보드값은 문자열 데이터임. #실제 숫자로 변환해야 하는데 이때 int() 함수를 사용함.\n",
        "while True:\n",
        "  print('input number : ')\n",
        "  menu = int(input())\n",
        "  if menu == 0: \n",
        "    break\n",
        "  elif menu == 1:\n",
        "    print('number one')\n",
        "  elif menu == 99:\n",
        "    continue\n",
        "  elif menu == 2:\n",
        "    print('number two')\n",
        "  else:\n",
        "    print('another number')\n"
      ],
      "metadata": {
        "id": "CRKksUPZVpQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for 반복문\n",
        "\n",
        "#for 반복문 사용 #조건을 이용해 반복적으로 작업을 수행할 때는 while 반복문, 앞서 배운 리스트나 튜플, 문자열에서 요소를 하나씩 꺼내서 사용할 땐 for 반복문. \n",
        "numbers = [1,2,3,4,5]\n",
        "for n in numbers:\n",
        "  print(n)\n",
        "\n",
        "#range()함수와 for 반복문 사용 #인자로 사용되는 시작값을 생략하는 경우 0부터 시작함.\n",
        "numbers = range(1,6)\n",
        "for n in numbers:\n",
        "  print(n)\n",
        "\n",
        "#여러 개의 변수에 자동 대입되는 for 반복문 #루프를 돌 때마다 자동으로 변수 x,y에 대입됨. #여러개의 요소를 가지는 자료형이면 자동으로 변수에 대입 가능함. #단, 요소 수와 자동으로 대입될 변수의 개수는 같아야 함.\n",
        "coord = [(0,0), (10,15), (20,25)]\n",
        "for x,y in coord:\n",
        "  print(x,y)\n",
        "\n",
        "#딕셔너리의 keys() 함수 #keys 리스트의 경우 딕셔너리 내부의 keys() 함수 이용.\n",
        "user = {'name' : 'Kei', 'age' : 35, 'nationality' : 'Korea'}\n",
        "user.keys()\n",
        "\n",
        "#딕셔너리의 key 리스트 출력\n",
        "for k in user.keys():\n",
        "  print(k)\n",
        "\n",
        "#딕셔너리의 values() 함수 사용 #value 리스트의 경우 딕셔너리 내부의 values() 함수 이용.\n",
        "user.values()\n",
        "\n",
        "#딕셔너리의 value 리스트 출력\n",
        "for v in user.values():\n",
        "  print(v)\n",
        "\n",
        "#딕셔너리의 items() 함수 사용 #데이터 쌍 리스트의 경우 딕셔너리 내부의 items() 함수 이용.\n",
        "user.items()\n",
        "\n",
        "#딕셔너리의 key/value 리스트 출력\n",
        "for k, v in user.items():\n",
        "  print(k,v)"
      ],
      "metadata": {
        "id": "Uncgt0G3Z-dO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#함수\n",
        "\n",
        "#함수란 하나의 기능을 수행하는 코드들의 집합입니다.\n",
        "#잘 짜인 함수는 단 하나의 목적을 가지며, 함수명으로 그 함수의 역할을 유추할 수 있어야 합니다.\n",
        "#물론 입력값과 결괏값이 없는 함수도 존재합니다.\n",
        "\n",
        "#우리가 만든 사용자 정의 함수, 시스템에 내장되어 바로 사용할 수 있는 내장 함수, 다른 개발자들이 라이브러리 형태로 모듈화 시켜 놓은 외장 함수가 있습니다. 3가지로 분류했지만 기본적으로 동일한 형태의 함수입니다.\n"
      ],
      "metadata": {
        "id": "aQimsNgscgLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#사용자 정의 함수\n",
        "\n",
        "#add() 함수 사용 #함수명은 변수명과 동일한 명명 규칙을 가지고 있음. \n",
        "def add(a,b):\n",
        "  return a+b\n",
        "add(10,20)\n",
        "\n",
        "#print_user() 함수 사용\n",
        "def print_user(user, score):\n",
        "  print(\"name : %s\" % user['name'])\n",
        "  print(\"age : %d\" % user['age'])\n",
        "  print(\"score : %d\" %score)\n",
        "user = {'name' : 'Kei' , 'age' : 35 }\n",
        "score = 85\n",
        "print_user(user, score)\n"
      ],
      "metadata": {
        "id": "PkNRE0bGCJZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#내장 함수\n",
        "\n",
        "#format() 함수 사용 #중괄호 사용. #별도로 모듈을 import하거나 함수를 정의하지 않아도 사용할 수 있음. #파이썬에서는 2가지 문자열 포매팅 방법을 제공함. #%d를 이용한 문자열 포매팅 방법과 format() 함수를 이용하는 방법임.\n",
        "print('integer : {} / float : {} / string : {}'.format(10, 3.14, \"hello\"))\n",
        "print('integer : {0} / float : {1} / string : {2}'.format(10, 3.14, \"hello\"))\n",
        "print('integer : {1} / float : {0} / string : {2}'.format(10, 3.14, \"hello\"))\n",
        "\n",
        "#enumerate() 함수 사용 #순서가 있는 자료형을 입력하면 인덱스를 포함한 요솟값을 반환함.\n",
        "numbers = [10, 11, 12, 13, 14]\n",
        "for idx, value in enumerate(numbers):\n",
        "  print('index:{}, value:{}'.format(idx, value))\n",
        "\n",
        "#str() 함수 사용 #입력으로 들어온 데이터를 문자열 객체로 반환함.\n",
        "str(10)\n",
        "type(str(10))\n",
        "str(\"hello\")\n",
        "str(\"hello\".upper()) #모든 문자를 대문자로 바꿈.\n",
        "str(\"HELLO\".lower()) #모든 문자를 소문자로 바꿈.\n",
        "str([1,2,3])\n",
        "\n",
        "#join() 함수 사용 #리스트에 포함되어 있는 요소들을 지정한 구분자로 구분해 문자열로 반환하는 함수.\n",
        "names =  ['Kei', 'Tonny', 'Grace', 'Jenny', 'Jaeyoo']\n",
        "','.join(names)\n",
        "\n",
        "#split() 함수 사용 #join() 함수와 반대로 문자열을 특정 구분자를 기준으로 분리해 리스트로 반환하는 함수.\n",
        "names_str = ','.join(names)\n",
        "names_split = names_str.split(',')\n",
        "names_split\n",
        "\n",
        "#id() 함수 사용 #객체를 입력받아 객체의 고유 주솟값(레퍼런스)을 반환하는 함수. #고유 주소값은 컴퓨터나 운영체제에 따라 달라질 수 있으니 다음 결과와 다르게 나온다고 실망할 필요는 없음.\n",
        "a = 10\n",
        "id(a)\n",
        "b = a\n",
        "id(b) # 주소가 동일하기 때문에 a와 b는 동일한 객체\n",
        "\n",
        "#find() 함수 사용 #특정 문자열을 찾기 위해 사용하는 함수. 찾으려는 문자열을 입력받으면 그 문자열의 시작 위치를 반환함. #해당 문자열을 찾지 못하면 -1을 반환함.\n",
        "str1 = \"I want to be a great programmer.\"\n",
        "str1.find(\"be\")\n",
        "str1.find(\"I\")\n",
        "str1.find(\"i\")\n",
        "\n",
        "#strip() 함수 사용 #주어진 문자열 양쪽 긑의 공백을 제거하는 함수.\n",
        "str1 = \" I want to be a great programmer. \"\n",
        "new_str = str1.strip()\n",
        "new_str\n",
        "\n",
        "#filter() 함수 사용 #개별 요소를 반복적으로 셀 수 있는 객체를 입력받아 각 요소를 함수로 수행한 후 결과가 True인 것만 묶어서 반환함.\n",
        "def is_even(number):\n",
        "  return number % 2 == 0 \n",
        "numbers = range(1, 21)\n",
        "even_list = list(filter(is_even, numbers)) # filter () 함수는 filter 객체 형태로 반환하기 때문에, 리스트 형태로 사용하려면 list 생성자를 사용해야 함.\n",
        "print(even_list)\n",
        "\n",
        "#lambda 함수 사용 #def보다 간결하게 함수를 정의할 수 있으며, 익명 함수이기 때문에 한 번 사용되고 나면 heap 메모리 영역에서 삭제되어 메모리 관리에 효율적인 장점이 있음. #내용과 구성이 간단한 함수의 경우 lambda 함수를 사용하는 것이 편리함.\n",
        "f = lambda x:x+2\n",
        "f(2)\n",
        "f(4)\n",
        "\n",
        "#filter() 함수와 lambda 함수 사용\n",
        "numbers = range(1,21)\n",
        "even_list = list(filter(lambda n:n%2==0, numbers))\n",
        "print(even_list)\n",
        "\n",
        "#map() 함수 사용 #개별 요소를 반복적으로 셀 수 있는 객체를 입력받아 각 요소를 함수로 수행한 후 결과를 묶어서 반환함. #게으른 연산을 함. 계산이 필요할 때만 메모리를 사용하기 때문에 메모리 절약 효과는 있음.\n",
        "def square(number):\n",
        "  return number ** 2\n",
        "numbers = range(1,5)\n",
        "square_list = list(map(square, numbers))\n",
        "print(square_list)\n",
        "\n",
        "#map() 함수와 lambda 함수 사용\n",
        "numbers = range(1,5)\n",
        "square_list = list(map(lambda x : x**2, numbers))\n",
        "print(square_list)\n"
      ],
      "metadata": {
        "id": "eBT2ozgvCWGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#외장 함수     #외장 함수는 클래스와 모듈 형태로 묶여 있습니다. #외장 함수를 사용하기 위해서는 import 키워드를 사용하여 해당 모듈을 불러와야 합니다.\n",
        "\n",
        "#sys.argv 사용 #sys는 파이썬 인터프리터와 관련된 정보와 기능을 제공하는 모듈. 특히 명령행에서 인수를 전달받기 위해 많이 사용함.\n",
        "#python 'hello' 10\n",
        "#import sys\n",
        "#print(sys.argv)\n",
        "#msg = sys.argv[1]\n",
        "#cnt = int(sys.argv[2])\n",
        "#\n",
        "#for i in range(cnt):\n",
        "#  print(i, msg)\n",
        "\n",
        "#sys.exit() 함수 사용\n",
        "#import sys\n",
        "#for n in range(100):\n",
        "#  print(n)\n",
        "#  if n == 10:\n",
        "#    sys.exit()\n",
        "\n",
        "#(pickle) 객체를 파일로 저장하는 예 #pickle 모듈은 파이썬 객체를 파일로 저장하고 메모리로 읽어올 수 있도록 도와주는 모듈. #dump() 함수를 이용해 리스트와 딕셔너리 객체를 파일로 저장하는 예제.\n",
        "import pickle\n",
        "f = open('setting.txt', 'wb') # wb: 바이너리 쓰기\n",
        "setting = [{'title' : 'python program'}, {'author' : 'Kei'}] \n",
        "pickle.dump(setting, f)\n",
        "f.close()\n",
        "\n",
        "#(pickle) 파일로 저장된 객체를 읽어오는 예 #load() 함수를 이용해 파일로 저장되어 있는 리스트와 딕셔너리 객체를 메모리로 읽어와 출력하는 예제\n",
        "import pickle \n",
        "f = open('setting.txt', 'rb')\n",
        "setting = pickle.load(f)\n",
        "f.close()\n",
        "print(setting)\n",
        "\n",
        "#time.time() 함수 사용 #time 모듈은 시스템이 제공하는 시간과 관련된 유용한 함수들을 포함하고 있음. #UTC 시간대를 사용해 현재 시간을 실수 형태로 반환. 1970년 1월 1일 0시 0분 0초를 기준으로 경과한 시간을 초 단위로 반환.\n",
        "import time\n",
        "time.time()\n",
        "\n",
        "#time.localtime() 함수 사용\n",
        "import time\n",
        "time.localtime(time.time())\n",
        "\n",
        "#time.strftime() 함수 사용\n",
        "import time\n",
        "lt = time.localtime(time.time())\n",
        "time.strftime('%Y/%m/%d %H:%M:%S', lt)\n",
        "\n",
        "#시간 관련 포매팅 문자 : %(Y, m, d, B, b, A, a, H, l, p, M, S)\n",
        "\n",
        "#random.random() 함수 사용 #random 모듈은 난숫값을 생성하는 기능과 다양한 랜덤 관련 함수를 제공함. #random() 함수를 사용하면 0에서 1사이의 실숫값을 랜덤으로 반환함.\n",
        "import random\n",
        "random.random()\n",
        "\n",
        "#time.uniform() #uniform() 함수를 사용하면 임의로 생성되는 실수의 범위를 정할 수 있음. #두번째 인잣값은 난수 생성 범위에 들어가지 않음.\n",
        "import random\n",
        "random.uniform(1, 2)\n",
        "\n",
        "#time.randint() #randint() 함수는 2개 인자로 난수 범위를 지정해서 정수 난수를 생성함. #두번째 인잣값이 난수 생성 범위에 들어감.\n",
        "import random\n",
        "random.randint(1, 5)\n"
      ],
      "metadata": {
        "id": "kcn8J__sF1Ab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#클래스\n",
        "\n",
        "#클래스를 정의하기 위해서는 class 키워드를 사용하며, 내부에 메서드와 인스턴스 변수를 정의해서 사용할 수 있습니다.\n",
        "\n",
        "#챗봇 객체 생성 #클래스명의 첫 글자는 대문자를 사용함. #함수(메서드)의 첫 번째 인자로 반드시 self 키워드를 사용해야 함.\n",
        "class Chatbot:\n",
        "  def sayHello(self):\n",
        "    print(\"say hello\")\n",
        "  def sayMyName(self):\n",
        "    print(\"My name is Kbot :D\")\n",
        "chatbot = Chatbot()  # 인스턴스를 생성함.\n",
        "chatbot.sayHello()\n",
        "chatbot.sayMyName()\n"
      ],
      "metadata": {
        "id": "FN1VNR-PU40q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#생성자 및 소멸자\n",
        "\n",
        "#파이썬에서는 인스턴트가 생성될 때 자동으로 호출되는 생성자라는 메서드를 제공합니다.\n",
        "#생성자 메서드명은 사용자가 임의로 변경할 수 없으며, 생성자 메서드로 __init__을 사용합니다.\n",
        "#생성자는 인스턴스가 생성되는 시점에 실행되기 때문에 해당 객체를 동작시키기 위한 사전 작업을 하게 됩니다.\n",
        "\n",
        "#파이썬은 인스턴트가 소멸될 때 자동으로 호출되는 소멸자라는 메서드를 제공합니다.\n",
        "#생성자와 마찬가지로 메서드명이 정해져 있으며, __del__을 사용하며, 생성자와 다르게 인자를 사용할 수 없습니다.\n",
        "#주로 객체가 사용하고 남은 메모리를 깨끗하게 청소하는 작업을 합니다.\n",
        "\n",
        "#생성자 및 소멸자 호출\n",
        "class SimpleObj:\n",
        "  def __init__(self):\n",
        "    print('call __init__()')\n",
        "  def __del__(self):\n",
        "    print('call__del__()')\n",
        "obj = SimpleObj()\n",
        "print('obj instance is alive...')\n",
        "del obj  #del로 해당 인스턴스 객체를 해제할 수 있음.\n"
      ],
      "metadata": {
        "id": "AJbZQN4jiKbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#메서드와 인스턴스 변수\n",
        "\n",
        "#일반 함수와 동일하지만, 인스턴스 객체가 갖고 있는 메서드에 접근하기 위해 첫 번째 인자는 반드시 self 키워드를 사용해야 합니다.\n",
        "\n",
        "#사칙 연산 클래스\n",
        "class Calc:\n",
        "  def __init__(self, init_value):  #입력값이 self가 아닌 init_value에 저장됨. self는 인스턴스 내부에서 자신을 참조하기 위해 사용하는 용도이기 때문.\n",
        "    self.value = init_value  #인스턴스 변수로 사용하기 위해서는 self 키워드를 사용해야 함.\n",
        "  def add(self, n): \n",
        "    return self.value + n\n",
        "  def sub(self, n):\n",
        "    return self.value - n\n",
        "  def mul(self, n):\n",
        "    return self.value * n\n",
        "  def div(self, n):\n",
        "    return self.value / n\n",
        "cal = Calc(100)\n",
        "print(\"value = {0}\".format(cal.value))\n",
        "a = cal.add(100)\n",
        "b = cal.sub(50)\n",
        "c = cal.mul(2)\n",
        "d = cal.div(2)\n",
        "print(\"a={0}, b={1}, c={2}, d={3}\".format(a, b, c, d))\n"
      ],
      "metadata": {
        "id": "_EpIeA79mD9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모듈\n",
        "\n",
        "# 모듈이란 여러 가지 함수나 클래스 등을 기능이나 목적별로 모아놓은 파일입니다.\n",
        "\n",
        "#calc 모듈(calc.py)\n",
        "def add(a, b): return a + b\n",
        "def sub(a, b): return a - b\n",
        "def mul(a, b): return a * b\n",
        "def div(a, b): return a / b\n",
        "\n",
        "#calc 모듈 사용 #직접 만든 모듈이므로 모듈 파일과 실행하는 소스 파일이 동일한 경로에 있어야 함.\n",
        "#import calc\n",
        "#a = calc.add(10, 20)\n",
        "#print(\"add = {}\".format(a))\n",
        "#b = calc.mul(10,2)\n",
        "#print(\"mul = {}\".format(b))\n",
        "\n",
        "#calc 모듈 사용 #모듈에서 불러올 함수를 직접 지정하는 방법 #from 키워드와 import 키워드를 함께 사용\n",
        "#from calc import add, mul\n",
        "a = add(10, 20)\n",
        "print(\"add = {}\".format(a))\n",
        "b = mul(10, 2)\n",
        "print(\"add = {}\".format(b))\n"
      ],
      "metadata": {
        "id": "cP5Agjy0oswZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#예외 처리\n",
        "\n",
        "#기본적인 오류 처리만 잘해도 예외 상황으로 프로그램이 죽어버리는 현상을 많이 줄일 수 있습니다.\n",
        "#파이썬에서는 이런 예외 처리를 할 수 있도록 try-except 구문을 문법적으로 제공하고 있습니다.\n",
        "#예외가 발생하면 그 즉시 except 구문으로 코드 흐름이 점프하게 됩니다. 보통 except 구문에는 예외가 발생했을 때 예외 처리를 할 수 있는 코드가 들어있습니다.\n",
        "#finally 구문은 try 구문 수행 도중 예외 발생 여부와 상관없이 항상 실행되기 때문에 리소스 해제를 위해 많이 사용합니다. 리소스 해제가 필요 없는 경우에는 finally 구문을 생략할 수 있습니다.\n",
        "\n",
        "#division by zero 예외 처리 #최상위 오류 내용인 Exception을 사용하면 모든 오류 내용의 예외 처리가 가능합니다.\n",
        "try:\n",
        "  a = 10\n",
        "  b = 0\n",
        "  c = a / b\n",
        "  print(c)\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "\n",
        "#여러 개의 예외 처리 #오류 내용에 따라 예외 처리를 다르게 하고 싶은 경우\n",
        "try:\n",
        "  a = 10\n",
        "  b = 'zero'\n",
        "  c = a / b\n",
        "except ZeroDivisionError as e:\n",
        "  print(e)\n",
        "except TypeError as e:\n",
        "  print(e)\n",
        "\n",
        "#파일을 안전하게 사용하는 예\n",
        "import pickle \n",
        "f = open('setting.txt','wb')\n",
        "try:\n",
        "  setting = [ {'title' : 'python program'}, {'author' : 'Kei'}]\n",
        "  pickle.dump(setting, f)\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "finally:\n",
        "  f.close()\n",
        "  "
      ],
      "metadata": {
        "id": "8foaSRpKDhtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 엑셀 파일을 읽고 쓰는 방법\n",
        "\n",
        "# 챗봇의 학습 데이터를 데이터베이스에 저장하기 위해 학습 프로그램을 만드는 것도 좋지만 우리는 간편하게 정해진 엑셀 양식에 질문과 답변을 정리해서 데이터베이스에 저장할 것입니다.\n",
        "# OpenPyXL 모듈을 사용하면 엑셀 2010 파일을 읽고 쓸 수 있습니다. 하지만 파이썬에서 기본적으로 제공하지 않기 때문에 모듈을 직접 설치해야 합니다.\n",
        "# 워크북: 엑셀 문서, 하나 이상의 워크시트를 가지고 있으며, 파일명이 워크북의 이름이 됩니다. \n",
        "# 현재 활성화되어 있는 워크시트인 경우 액티브시트라고 합니다.\n",
        "\n",
        "#엑셀 파일의 특정 셀 내용 읽어오기\n",
        "import openpyxl\n",
        "#wb = openpyxl.load_workbook('./sample.xlsx')\n",
        "#sheet = wb['Sheet1']\n",
        "#print(sheet.max_column, sheet.max_row)\n",
        "#print(sheet.cell(row=1, column=1).value)  # cell() 함수에서 셀의 위치는 반드시 1부터 시작해야 합니다. \n",
        "#print(sheet.cell(row=2, column=1).value)   # 함수를 호출할 때 인자 이름을 명시적으로 지정할 수 있습니다. 프로그램의 가독성이 높아지는 장점이 있습니다.\n",
        "#wb.close()    # 사용을 완료한 리소스는 반드시 닫아야 함.\n",
        "\n",
        "# 엑셀 파일의 모든 셀 내용 읽어오기\n",
        "import openpyxl\n",
        "#wb = openpyxl.load_workbook('./sample.xlsx')\n",
        "#sheet = wb['Sheet1']\n",
        "#for row in sheet.iter_rows(min_rows=2):         #iter_rows 함수를 이용해 워크시트 내의 모든 row 데이터를 탐색함. min_row 인자는 초기 탐색 시작 위치를 설정함.\n",
        "#  for cell in row:                              # 텍스트 헤더로 사용되는 첫 번째 행은 탐색하지 않습니다. min_row 인자를 생략하면 첫 번째 행부터 탐색을 시작함.\n",
        "#     print(cell_value)\n",
        "#  print('-'*10)\n",
        "#wb.close()\n",
        "\n",
        "# 엑셀 파일에서 지정한 셀 내용 읽어오기 # OpenPyXL모듈은 여러 셀에 접근할 때 슬라이싱 기능을 이용해 특정 범위를 지정할 수 있음.\n",
        "import openpyxl\n",
        "#wb = openpyxl.load_workbook('./sample.xlsx')\n",
        "#sheet = wb['Sheet1']\n",
        "#cells = sheet['A2':'C3']\n",
        "#for row in cells:\n",
        "#   for cell in row:      #열단위 데이터를 출력하기 위해 for 루프를 시작함.\n",
        "#     print(cell.value)\n",
        "#   print('-' * 10)\n",
        "#wb.close()\n",
        "\n",
        "#회원정보를 엑셀에 저장\n",
        "import openpyxl\n",
        "wb = openpyxl.Workbook()\n",
        "sheet = wb.active\n",
        "sheet.title = '회원정보'\n",
        "\n",
        "header_titles = ['이름', '전화번호']   # 표 헤더 컬럼 저장\n",
        "for idx, title in enumerate(header_titles):\n",
        "  sheet.cell(row=1, column=idx+1, value=title)   #cell() 함수는 셀 데이터를 가져와 출력할 수도 있지만, 원하는 셀에 데이터를 저장할 수도 있음.\n",
        "\n",
        "members = [('kei', '010-1234-1234'), ('hong', '010-4321-1234')]\n",
        "row_num = 2\n",
        "for r, member in enumerate(members):   # 회원정보 목록 탐색\n",
        "  for c,v in enumerate(member):    # 이름, 전화번호 컬럼 탐색\n",
        "    sheet.cell(row=row_num+r, column=c+1, value=v)\n",
        "wb.save('./members.xlsx')\n",
        "wb.close()\n"
      ],
      "metadata": {
        "id": "13FnTGQ0ENC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 분석을 위한 라이브러리\n",
        "# 넘파이\n",
        "\n",
        "# 넘파이 라이브러리는 C언어로 구현되어 있기 때문에 빠른 배열 처리와 고성능 수치 계산을 지원합니다.\n",
        "\n",
        "#넘파이 배열 생성 #배열을 생성하려면 넘파이 라이브러리의 array() 함수를 이용함.\n",
        "import numpy as np\n",
        "arr = np.array([1,2,3])\n",
        "print(arr)\n",
        "print(type(arr)) # numpy.ndarray 객체로 배열을 만들어 반환함.\n",
        "\n",
        "# 2*3 행렬 표현\n",
        "import numpy as np \n",
        "matrix = np.array([ [1,2,3], [4,5,6] ])\n",
        "print(matrix)\n",
        "\n",
        "# 2*3 행렬 덧셈 연산 # 행렬의 크기가 반드시 같아야 함.\n",
        "import numpy as numpy\n",
        "A = np.array([ [1,2], [3,4] ])\n",
        "B = np.array([ [1,1], [1,1] ])\n",
        "C = A + B\n",
        "print(C)\n",
        "\n",
        "# 3*2 행렬과 2*2 행렬의 곱셈 # matmul()함수를 제공함. # 배열의 크기가 서로 같아야 *와 + 연산자를 사용할 수 있음.\n",
        "import numpy as np\n",
        "A = np.array([ [1,2], [3,4], [5,6] ])\n",
        "B = np.array([ [2,3], [2,3] ])\n",
        "C = np.matmul(A, B)\n",
        "print(C)\n",
        "\n",
        "# 스칼라곱 \n",
        "import numpy as np\n",
        "A = np.array([ [1,2], [3,4] ])\n",
        "k = 10\n",
        "C = k * A\n",
        "print(C)\n"
      ],
      "metadata": {
        "id": "pqWfSCPDN6Sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 팬더스\n",
        "\n",
        "#시리즈, 데이터 프레임, 패널 등 세 가지 데이터 구조를 가지고 있습니다.\n",
        "\n",
        "# Series 객체 사용 # 1차원 데이터로서 각 데이터값과 대응하는 인덱스 지정 가능 #인덱스를 생략할 경우 인덱스 번호가 자동으로 할당됨.\n",
        "import pandas as pd\n",
        "numbers = pd.Series( [100, 200, 300])\n",
        "print(numbers)\n",
        "scores = pd.Series([90, 80, 99], index=['국어', '수학', '영어'])  # 이때 데이터로 사용될 리스트와 인덱스로 사용될 리스트의 크기가 동일해야 합니다.\n",
        "print(scores)\n",
        "print(scores.index)\n",
        "print(scores.values)\n",
        "print(scores.index[1], scores.values[1])\n",
        "\n",
        "#DataFrame 객체 사용 # 2차원 자료구조 # 실제로 딥러닝 모델의 학습 데이터는 2차원 구조로 구성되는 경우가 많아 데이터프레임을 많이 사용\n",
        "import pandas as pd\n",
        "temperatures = [[3.3, 34.5, 14.2, -10], [7.1, 32.1, 10.7, 2]]\n",
        "seasons = ['Spring', 'Summer', 'Fall', 'Winter']\n",
        "regions = ['Seoul', 'Pusan']\n",
        "data = pd.DataFrame(temperatures, index=regions, columns=seasons)\n",
        "print(data)\n",
        "print(\"=\"*50)\n",
        "print(data.index) # 행 방향 인덱스의 내용과 인덱스의 데이터 타입이 출력됨.\n",
        "print(data.columns) # 열 방향 인덱스의 내용과 인덱스의 데이터 타입이 출력됨.\n",
        "print(data.values) # 생성된 DataFrame 객체의 2차원 데이터 리스트를 출력함.\n",
        "print(\"=\"*50)\n",
        "print(data['Spring']['Seoul'])\n",
        "print(\"=\"*50)\n",
        "print(data.head(2))\n",
        "print(\"=\"*50)\n",
        "print(data.tail(1))\n",
        "\n",
        "#엑셀 파일 읽기\n",
        "import pandas as pd\n",
        "user_list = pd.read_excel('members.xlsx')\n",
        "print(user_list)\n"
      ],
      "metadata": {
        "id": "yXxm5Mq68CB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 맷플롯립\n",
        "\n",
        "# 데이터를 플롯이나 차트로 시각화할 수 있도록 도와주는 도구입니다.\n",
        "\n",
        "# 직선그래프\n",
        "import matplotlib.pyplot as plt\n",
        "x = [a for a in range(0, 11)]  # 리스트 내포: 리스트 안에 for 구문을 이용해서 직관적으로 리스트를 생성할 수 있음.\n",
        "y = list(range(0,11))  # 윗줄과 결과 동일\n",
        "print('x축', x)\n",
        "print('y축', y)\n",
        "plt.plot(x,y)\n",
        "plt.show()\n",
        "\n",
        "# 2차 함수 그래프\n",
        "import matplotlib.pyplot as plt\n",
        "f = lambda x: x**2\n",
        "x = [x for x in range(-10,10)]\n",
        "y = [f(y) for y in range(-10,10)]\n",
        "print('x축', x)\n",
        "print('y축', y)\n",
        "plt.plot(x, y)\n",
        "plt.show()\n",
        "\n",
        "# 계절별 온도 바차트 # barh(): 가로방향 바차트\n",
        "import matplotlib.pyplot as plt\n",
        "temperatures = [3.3, 34.5, 14.2, -10]\n",
        "x = list(range(4))\n",
        "x_labels = ['Spring', 'Summer', 'Fall', 'Winter']\n",
        "plt.title('Bar Chart')\n",
        "plt.bar(x, temperatures)\n",
        "plt.xticks(x,x_labels)\n",
        "plt.yticks(sorted(temperatures))  # sorted() 함수는 인자로 들어온 리스트 요소를 오름차순으로 정렬해주는 역할을 함.\n",
        "plt.xlabel('season')\n",
        "plt.ylabel('temperature')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "MKEsXbd8-XlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CHAPTER 3 토크나이징"
      ],
      "metadata": {
        "id": "WST8c8kYDhSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#토크나이징\n",
        "\n",
        "#우리가 일상에서 사용하는 언어를 자연어라고 합니다. 컴퓨터 분야에서는 자연어 의미를 분석해 컴퓨터가 처리할 수 있도록 하는 일을 자연어 처리 혹은 NLP라고 합니다.\n",
        "#가장 기본이 되는 단어들을 토큰이라고 합니다. 토큰의 단위는 토크나이징 방법에 따라 달라질 수 있지만 일반적으로 일정한 의미가 있는 가장 작은 정보 단위로 결정됩니다.\n",
        "#토크나이징은 문장 형태의 데이터를 처리하기 위해 제일 처음 수행해야 하는 기본적인 작업이며, 주로 텍스트 전처리 과정에서 사용됩니다.\n"
      ],
      "metadata": {
        "id": "TyTcrTZrDk_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# KoNLPy\n",
        "\n",
        "#KoNLPy는 기본적인 한국어 자연어 처리를 위한 파이썬 라이브러리입니다.\n",
        "#형태소는 일정한 의미가 있는 작은 말의 단위입니다. 형태소를 토큰 단위로 사용할 경우 단어와 품사 정보를 같이 활용할 수 있기 때문에 효과적입니다.\n",
        "#한국어의 복잡한 특성에 따라 문장에서 형태소를 분석할 수 있는 도구인, 형태소 분석기가 필요합니다. 이는 다양한 언어적 속성의 구조를 파악해줍니다.\n",
        "#한국어의 복잡한 문법적인 구조 때문에 완벽한 형태소 분석기를 개발하는 일은 쉽지 않습니다. 다행히 KoNLPy의 내부 모듈에서는 사용하기 좋은 몇 가지 형태소 분석기를 통합해 라이브러리 형태로 제공합니다.\n",
        "\n",
        "!pip install koNLpy\n",
        "\n"
      ],
      "metadata": {
        "id": "Pe-pbShspKjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# KKMa\n",
        "\n",
        "# '꼬꼬마'라 발음하며, GPL v2라이선스를 따릅니다.\n",
        "# 함수 설명: morphs(), nouns(), pos(phrase, flatten=True), sentences()\n",
        "\n",
        "# 꼬꼬마 형태소 분석기 사용\n",
        "from konlpy.tag import Kkma\n",
        "kkma = Kkma()\n",
        "text = \"아버지가 방에 들어갑니다.\"\n",
        "morphs = kkma.morphs(text)  # 인자로 입력한 문장을 형태소 단위로 토크나이징함. \n",
        "print(morphs)\n",
        "pos = kkma.pos(text)  # 형태소와 품사 태그 추출\n",
        "print(pos)\n",
        "nouns = kkma.nouns(text)  # 명사만 추출\n",
        "print(nouns)\n",
        "sentences = \"오늘 날씨는 어때요? 내일은 덥다던데.\"\n",
        "s = kkma.sentences(sentences)  # 문장 분리\n",
        "print(s)\n"
      ],
      "metadata": {
        "id": "CDAwUYVyqEhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Komoran\n",
        "\n",
        "#다른 형태소 분석기와 다르게 공백이 포함된 형태소 단위로도 분석이 가능해 많이 사용합니다.\n",
        "\n",
        "#Komoran 형태소 분석기 사용\n",
        "from konlpy.tag import Komoran\n",
        "komoran = Komoran()\n",
        "text = \"아버지가 방에 들어갑니다.\"\n",
        "morphs = komoran.morphs(text)\n",
        "print(morphs)\n",
        "pos = komoran.pos(text)  # 형태소와 품사 태그 추출\n",
        "print(pos)\n",
        "nouns = komoran.nouns(text)  # 명사만 추출\n",
        "print(nouns)\n"
      ],
      "metadata": {
        "id": "_nAGx_sNspPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Okt\n",
        "\n",
        "#Okt는 빅데이터에서 간단한 한국어 처리를 통해 색인어를 추출하는 목표를 갖고 있기 때문에 완전한 수준의 형태소 분석을 지향하지 않습니다.\n",
        "\n",
        "#Okt 형태소 분석기 사용\n",
        "from konlpy.tag import Okt\n",
        "okt = Okt()\n",
        "text = \"아버지가 방에 들어갑니다.\"\n",
        "morphs = okt.morphs(text)\n",
        "print(morphs)\n",
        "pos = okt.pos(text)  # 형태소와 품사 태그 추출\n",
        "print(pos)\n",
        "nouns = okt.nouns(text)  # 명사만 추출\n",
        "print(nouns)\n",
        "\n",
        "text = '오늘 날씨가 좋아욬ㅋㅋ'\n",
        "print(okt.normalize(text))\n",
        "print(okt.phrases(text))"
      ],
      "metadata": {
        "id": "jayHm3KMvIy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from locale import nl_langinfo\n",
        "# 사용자 사전 구축\n",
        "\n",
        "#새롭게 생겨나는 단어나 문장은 형태소 분석기에서 인식이 안 되는 경우가 많습니다. 이는 인식률 저하의 원인이 됩니다.\n",
        "#최근에는 사람이 일일이 사용자 사전을 구축하지 않더라고 데이터 기반으로 새로운 단어를 추출해 적용하는 기술이 개발되고 있지만 난이도가 맞지 않기 때문에 설명은 생략.\n",
        "\n",
        "#미등록 단어 형태소 분석\n",
        "komoran = Komoran()\n",
        "text = '우리 챗봇은 엔엘피를 좋아해.'\n",
        "pos = komoran.pos(text)\n",
        "print(pos)\n",
        "\n",
        "#단어 Tab 품사\n",
        "#엔엘피  NNG -> user_disc.tsv 파일에 저장\n",
        "\n",
        "text = '우리 챗봇은 엔엘피를 좋아해.'\n",
        "pos = komoran.pos(text)\n",
        "print(pos)\n"
      ],
      "metadata": {
        "id": "Vu_Se6DNv66u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CHAPTER 4 임베딩"
      ],
      "metadata": {
        "id": "aV6EgEp2xGcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 임베딩\n",
        "\n",
        "\n",
        "# 컴퓨터는 수치 연산만 가능하기 때문에 자연어를 숫자나 벡터 형태로 변환할 필요가 있습니다. 이런 일련 과정을 자연어 처리 분야에서는 임베딩이라고 합니다.\n",
        "\n",
        "# 다른 딥러닝 모델의 입력값으로 많이 사용합니다.\n",
        "\n",
        "# 임베딩 품질이 좋다면 단순한 모델로도 훌륭한 결과를 얻을 수 있습니다.\n",
        "\n",
        "# 임베딩 기법에는 문장 임베딩과 단어 임베딩이 있습니다. \n",
        "\n",
        "# 문장 임베딩은 문장 전체를 벡터로 표현하는 방법이며, 단어 임베딩은 개별 단어를 벡터로 표현하는 방법입니다. \n",
        "# 장점) 문장 임베딩의 경우 전체 문장의 흐름을 파악해 벡터로 변환하기 때문에 문맥적 의미를 지니는 장점이 있습니다. 그런 이유로 단어 임베딩에 비해 품질이 좋으며, 상용 시스템에 많이 사용됩니다.\n",
        "# 단점) 하지만 임베딩하기 위해 많은 문장 데이터가 필요하며 학습하는 데 비용이 많이 들어갑니다.\n",
        "\n",
        "# 단점) 단어 임베딩은 의미가 다르더라도 단어의 형태가 같아면 동일한 벡터값으로 표현되는 단점이 있습니다.\n",
        "# 장점) 하지만 문장 임베딩에 비해 학습 방법이 간단해 여전히 실무에서 많이 사용합니다.\n",
        "\n",
        "# 이 책에서는 초심자들이 따라할 수 있는 환경에서 챗봇 엔진을 만들어야 하기 때문에 단어 임베딩만 다룰 것입니다.\n"
      ],
      "metadata": {
        "id": "NBRrQKrA2kUX"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 단어 임베딩\n",
        "\n",
        "# 단어 임베딩은 말뭉치에서 각각의 단어를 벡터로 변환하는 기법을 의미합니다.\n"
      ],
      "metadata": {
        "id": "wFjq7gmf3zCt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 원-핫 인코딩\n",
        "\n",
        "# 원-핫 인코딩은 단어를 숫자 벡터로 변환하는 가장 기본적인 방법입니다. 나온 결과를 원-핫 벡터라 하며, 전체 요소 중 단 하나의 값만 1이기 때문에 희소 벡터라고 합니다.\n",
        "\n",
        "# 원-핫 인코딩을 하기 위해서는 단어 집합이라 불리는 사전을 먼저 만들어야 합니다. 말뭉치에 존재하는 모든 단어의 수가 원-핫 벡터의 차원을 결정합니다.\n",
        "# 사전이 구축이 되었다면 사전 내 단어 순서대로 고유한 인덱스 번호를 부여합니다. 단어의 인덱스 번호가 1의 값을 가지는 요소의 위치가 됩니다.\n",
        "\n",
        "!pip install KoNLPy\n",
        "from konlpy.tag import Komoran\n",
        "import numpy as np\n",
        "\n",
        "komoran = Komoran()  # 토크나이징\n",
        "text = \"오늘 날씨는 구름이 많아요.\"\n",
        "\n",
        "nouns = komoran.nouns(text)  # 명사만 추출\n",
        "print(nouns)\n",
        "\n",
        "dics = {}   # 단어 사전 구축 및 단어별 인덱스 부여\n",
        "for word in nouns:\n",
        "  if word not in dics.keys():   # 이미 저장된 단어는 다시 사전에 저장하지 않음.\n",
        "    dics[word] = len(dics)\n",
        "print(dics)\n",
        "\n",
        "nb_classes = len(dics)    # 원-핫 인코딩\n",
        "targets = list(dics.values())   # numpy 사용해야 하므로 리스트 형태로 변환\n",
        "one_hot_targets = np.eye(nb_classes)[targets]   # eye(): 단위행렬 생성, [targets(변수이름)]-> 단위행렬의 순서를 단어 사전의 순서에 맞게 정렬\n",
        "\n",
        "print(one_hot_targets)\n",
        "\n",
        "\n",
        "#간단한 구현 방법에 비해 좋은 성능을 가지기 때문에 많은 사람이 사용하고 있습니다. ~ 그러나, 원-핫 벡터는 대부분의 요소가 0의 값을 가지고 있으므로 비효율적입니다.\n"
      ],
      "metadata": {
        "id": "6_fYdT4g36fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2784037c-22e2-4d91-9e90-4cbed4034c62"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting KoNLPy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from KoNLPy) (4.9.1)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from KoNLPy) (1.21.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (453 kB)\n",
            "\u001b[K     |████████████████████████████████| 453 kB 45.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->KoNLPy) (4.1.1)\n",
            "Installing collected packages: JPype1, KoNLPy\n",
            "Successfully installed JPype1-1.4.0 KoNLPy-0.6.0\n",
            "['오늘', '날씨', '구름']\n",
            "{'오늘': 0, '날씨': 1, '구름': 2}\n",
            "[[1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 분산 표현(= 밀집 표현) (<-> 희소 표현)\n",
        "\n",
        "# 각 단어 간의 유사성을 잘 표현하면서도 벡터 공간을 절약할 수 있는 방법을 고안했는데, 이를 분산표현이라고 합니다. 한 단어의 정보가 특정 차원에 표현되지 않고 여러 차원에 분산되어 표현된다 하여 붙여진 이름입니다.\n",
        "# 분산 표현은 희소 표현(ex) 원-핫 인코딩)에 비해 장점이 많습니다. 따라서 단어 임베딩 기법에서 많이 사용하고 있는 방식입니다.\n",
        "\n",
        "# 차원의 저주 문제를 줄일 수 있음. (입력 데이터의 차원이 너무 높아지면 신경망 모델의 학습이 어려워진다는 뜻)\n"
      ],
      "metadata": {
        "id": "eT0OIcg19-qy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Word2Vec 모델 학습 예제\n",
        "\n",
        "# Word2Vec\n",
        "\n",
        "# 2013년 구글에서 발표했으며 가장 많이 사용하고 있는 단어 임베딩 모델입니다. Word2Vec 모델은 CBOW와 skip-gram 두 가지 모델로 제안되었습니다.\n",
        "# CBOW : 맥락이라 표현되는 주변 단어들을 이용해 타깃 단어를 예측하는 신경망 모델입니다.  (타깃 단어의 손실만 계산하면 되기 때문에 학습 속도가 빠른 장점이 있습니다.)\n",
        "# skip-gram : 반대로 하나의 타깃 단어를 이용해 주변 단어들을 예측하는 신경망 모델입니다. (예측해야 하는 맥락이 많아져, 단어 분산 표현력이 우수해 CBOW 모델에 비해 임베딩 품질이 우수합니다.)\n",
        "# + window: 앞뒤로 몇 개의 단어까지 확인할 지 결정할 때, 그 해당하는 범위.\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "from konlpy.tag import Komoran\n",
        "import time\n",
        "\n",
        "def read_review_data(filename):    # 데이터 읽어옴 (교재에서는 네이버 영화 리뷰(nsmc))\n",
        "  with open(filename, 'r') as f:\n",
        "    data = [line.split('\\t') for line in f.read().splitlines()]\n",
        "    data = data[1:]\n",
        "  return data\n",
        "\n",
        "start = time.time()   # 학습 시간 측정 시작\n",
        "\n",
        "print('1) 말뭉치 데이터 읽기 시작')   # 리뷰 파일 읽어오기\n",
        "review_data = read_review_data('.ratings.txt')\n",
        "print(len(review_data))\n",
        "print('1) 말뭉치 데이터 읽기 완료 : ', time.time() - start)\n",
        "\n",
        "print('2) 형태소에서 명사만 추출 시작')   # 문장 단위로 명사만 추출해 학습 입력 데이터로 만듦\n",
        "komoran = Komoran()\n",
        "docs = [komoran.nouns(sentence[1]) for sentence in review_data]\n",
        "print('2) 형태소에서 명사만 추출 완료 : ', time.time() - start)\n",
        "\n",
        "print('3) Word2Vec 모델 학습 시작')   # Word2Vec 모델 학습 시작\n",
        "model = Word2Vec(sentences=docs, size=200, window=4, hs=1, min_count=2, sg=1)  #하이퍼파라미터: 학습시 필요한 세팅값. 그냥 인자나 파라미터와는 다름.\n",
        "print('3) Word2Vec 모델 학습 완료 : ', time.time() - start)\n",
        "\n",
        "print('4) 학습된 모델 저장 시작')   # 모델 저장\n",
        "model.save('nvmc.model')  #하이퍼파라미터: 학습시 필요한 세팅값. 그냥 인자나 파라미터와는 다름.\n",
        "print('4) 학습된 모델 저장 완료 : ', time.time() - start)\n",
        "\n",
        "print(\"corpus_count : \", model.corpus_count)   # 학습된 말뭉치 수, 코퍼스 내 전체 단어 수\n",
        "print(\"corpus_total_words : \", model.corpus_total_words)\n"
      ],
      "metadata": {
        "id": "5ziydFAe4mnd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5336edb-84cd-4d48-98f4-b083f87d9f75"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1) 말뭉치 데이터 읽기 시작\n",
            "200000\n",
            "1) 말뭉치 데이터 읽기 완료 :  0.5605001449584961\n",
            "2) 형태소에서 명사만 추출 시작\n",
            "2) 형태소에서 명사만 추출 완료 :  139.23503136634827\n",
            "3) Word2Vec 모델 학습 시작\n",
            "3) Word2Vec 모델 학습 완료 :  184.09061527252197\n",
            "4) 학습된 모델 저장 시작\n",
            "4) 학습된 모델 저장 완료 :  187.3279218673706\n",
            "corpus_count :  200000\n",
            "corpus_total_words :  1076896\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Word2Vec 모델 활용\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "model = Word2Vec.load('nvmc.model')   # 모델 로딩\n",
        "print(\"corpus_total_words : \", model.corpus_total_words)\n",
        "\n",
        "print('사랑 : ', model.wv['사랑'])   # '사랑'이란 단어로 생성한 단어 임베딩 벡터\n",
        "\n",
        "print(\"일요일 = 월요일\\t\", model.wv.similarity(w1='일요일', w2='월요일'))  # 단어 유사도 계산\n",
        "print(\"안성기 = 배우\\t\", model.wv.similarity(w1='안성기', w2='배우'))\n",
        "print(\"대기업 = 삼성\\t\", model.wv.similarity(w1='대기업', w2='삼성'))\n",
        "print(\"일요일 = 삼성\\t\", model.wv.similarity(w1='일요일', w2='삼성'))\n",
        "print(\"히어로 = 삼성\\t\", model.wv.similarity(w1='히어로', w2='삼성'))\n",
        "\n",
        "print(model.wv.most_similar(\"안성기\", topn=5))\n",
        "print(model.wv.most_similar(\"시리즈\", topn=5))\n",
        "\n",
        "# 놀라울 정도로 유사한 단어를 찾는 경우도 있지만 이해하기 힘든 결과를 출력하는 경우도 있습니다.\n",
        "# 이는 주제에 맞는 말뭉치 데이터가 부족해서 생기는 현상이니 품질 좋은 말뭉치 데이터를 학습하면 임베딩 성능이 많이 좋아집니다.\n",
        "\n",
        "# 모델 학습 시 신경망 내 각 노드의 초기 가중치가 랜덤으로 설정됩니다. 따라서 모델 학습을 할 때마다 단어 임베딩 벡터값이 변경됩니다. 그러므로 실습을 할 때 이 책의 결과와 다르게 보일 수 있습니다.\n"
      ],
      "metadata": {
        "id": "3xqd0wBY8_Yc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f27a5ebb-8f9d-4f1f-b16f-7ef50d61f85e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "corpus_total_words :  1076896\n",
            "사랑 :  [-0.20849799 -0.11614079  0.1716568  -0.01359271 -0.46728575  0.2677322\n",
            " -0.16806306  0.27442902 -0.09635262 -0.16780251  0.2412301   0.19705561\n",
            " -0.13989115 -0.1907554  -0.06082692 -0.10589017 -0.00886198 -0.17940554\n",
            "  0.32659295  0.4696243  -0.16797319  0.16889335 -0.06383163  0.10989545\n",
            " -0.06998409  0.42558563 -0.29991868  0.31809568  0.1112565   0.29718283\n",
            " -0.31653705 -0.1060572  -0.21811356  0.20656529  0.20638865 -0.03666208\n",
            " -0.08569262 -0.14589177 -0.15359065 -0.34672529  0.15401697  0.21668564\n",
            "  0.32238433  0.17036293 -0.06447782 -0.1344266  -0.0639123  -0.39506462\n",
            " -0.0698384  -0.44364586 -0.17361946  0.19418028  0.29491383  0.2955315\n",
            " -0.28722787 -0.05028236  0.09250993  0.25404543  0.05519905 -0.04732883\n",
            "  0.13773511  0.14179462  0.13022028 -0.12465102 -0.09549876 -0.12215421\n",
            "  0.25558287 -0.17086947 -0.10893801 -0.16487502  0.12232272  0.11118476\n",
            " -0.21263625 -0.14079584 -0.37990743 -0.28132397  0.20626204 -0.06610727\n",
            "  0.09531366  0.06403174 -0.367519    0.10853066 -0.3340768  -0.02992818\n",
            "  0.00326889  0.15365545  0.152531   -0.12939478 -0.26735005 -0.15094101\n",
            "  0.09777771  0.02551651  0.24449594  0.14097545  0.02658455 -0.18322456\n",
            " -0.09267251  0.1235223  -0.29550576 -0.14907575  0.24201204 -0.11858921\n",
            "  0.29926908  0.04817802 -0.00304149 -0.1194639   0.13656648 -0.17597827\n",
            "  0.2690853   0.3369353  -0.11123825  0.16065453  0.13038328 -0.26712555\n",
            "  0.22796018  0.42339092  0.04282088  0.05819273  0.16617277 -0.03242269\n",
            "  0.0610912  -0.22419417  0.19865836 -0.11042334 -0.1062508   0.08250128\n",
            "  0.39294145 -0.11941899  0.07933444  0.07150722 -0.10290071  0.07117821\n",
            "  0.20396258 -0.16483773 -0.20164399 -0.17263152  0.17000967  0.39100954\n",
            "  0.03132117 -0.37579215 -0.08150106 -0.04905397 -0.21355256 -0.07453091\n",
            "  0.17303306  0.20172635  0.00278012 -0.08677898 -0.11816219  0.3571236\n",
            "  0.14242354  0.15170482  0.03690209 -0.20584728 -0.11165389 -0.26164496\n",
            " -0.17239268 -0.03661333 -0.05976948 -0.33229667  0.08872105 -0.38154924\n",
            "  0.21322823  0.08869548 -0.34044608  0.19618657  0.10352894  0.17598973\n",
            " -0.06431632  0.15074058  0.17651235  0.15642694  0.21931261 -0.296971\n",
            " -0.04591934 -0.07402626  0.286127    0.13649787 -0.27409238  0.21557122\n",
            "  0.4155541   0.07645529  0.24684119 -0.05251955 -0.3098574  -0.11781075\n",
            "  0.22181891 -0.07547654 -0.05765371 -0.00539825 -0.01736948  0.38925487\n",
            "  0.11889876 -0.33907098  0.24971072  0.33931604 -0.11366924 -0.00749862\n",
            " -0.2731609   0.1826801 ]\n",
            "일요일 = 월요일\t 0.69970214\n",
            "안성기 = 배우\t 0.5904065\n",
            "대기업 = 삼성\t 0.5355306\n",
            "일요일 = 삼성\t 0.32333082\n",
            "히어로 = 삼성\t 0.1498192\n",
            "[('정려원', 0.7227250337600708), ('김정학', 0.7173440456390381), ('씨야', 0.7147817611694336), ('장미희', 0.7136266827583313), ('박중훈', 0.7129794955253601)]\n",
            "[('캐리비안의 해적', 0.6763412952423096), ('더 울버린', 0.6512266993522644), ('비포 선셋', 0.645779550075531), ('러시아워', 0.6439064741134644), ('반지의 제왕', 0.6436456441879272)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CHAPTER 5 텍스트 유사도"
      ],
      "metadata": {
        "id": "lSJrzELlB6eu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 텍스트 유사도\n",
        "\n",
        "#4장에서 배운 임베딩으로 각 단어들의 벡터를 구한 다음 벡터 간의 거리를 계산하는 방법으로 단어 간의 의미가 얼마나 유사한지 계산할 수 있습니다. \n",
        "#문장 역시 단어들의 묶음이기 때문에 하나의 벡터로 묶어서 문장간의 유사도를 계산할 수 있습니다.\n",
        "\n",
        "#두 문장 간의 유사도를 계산하기 위해서는 문장 내에 존재하는 단어들을 수치화해야 합니다.\n",
        "#이때, 언어 모델에 따라 통계를 이용하는 방법(tf))과 인공 신경망을 이용하는 방법(Word2Vec)으로 나눌 수 있습니다. 인공 신경망 방식의 성능이 절대적으로 좋은 건 아닙니다.\n",
        "# (심심이 같은 봇은 스몰토크에 적합하도록 개발된 챗봇입니다. 가볍게 나누는 일상 대화에 필요한 모든 상황이나 대화를 일일이 Q&A 형태로 학습하는 것은 불가능에 가깝습니다.)\n",
        "\n"
      ],
      "metadata": {
        "id": "LuSV9_Z3MEMN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# n-gram 유사도 \n",
        "\n",
        "# n-gram: 주어진 문장에서 n개의 연속적인 단어 시퀀스를 의미합니다. n개의 단어를 토큰으로 사용합니다.\n",
        "#이는 이웃한 단어의 출현 횟수를 통게적으로 표현해 텍스트의 유사도를 계산하는 방법입니다. 손쉬운 구현 방식에 비해 학습 말뭉치 품질만 좋다면 괜찮은 성능을 보여줍니다.\n",
        "# 이를 통해 논문 인용이나 도용 정도를 조사할 수 있습니다.\n",
        "\n",
        "#similarity = tf(A,B) / tokens(A)\n",
        "# tf: 두 문장 A와 B에서 동일한 토큰의 출현 빈도\n",
        "# tokens: 해당 문장에서 전체 토큰 수.\n",
        "#즉, 기준이 되는 문장 A에서 나온 전체 토큰 중에서 A와 B에 동일한 토큰이 얼마나 있는지 비율로 표현한 수식입니다.\n",
        "\n",
        "#TDM: 단어 문서 행렬\n",
        "# 현재 문장 단위로 유사도를 계산하고 있기 때문에 문장이라고 표현했지만, 실무에서는 문서 단위로 유사도를 구하는 경우가 더 많으며, 해당 문서에서 단어들이 얼마나 나오는지 출현 빈도를 행렬로 표현합니다.\n"
      ],
      "metadata": {
        "id": "qH7z9MqYaMii"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2-gram 유사도 계산\n",
        "\n",
        "!pip install KoNLPy\n",
        "from konlpy.tag import Komoran\n",
        "\n",
        "#어절 단위 n-gram\n",
        "def word_ngram(bow, num_gram):\n",
        "  text = tuple(bow)    # 추출된 토큰들은 투플 형태로 반환됨.\n",
        "  ngrams = [text[x:x + num_gram] for x in range(0,len(text))]\n",
        "  return tuple(ngrams)\n",
        "\n",
        "#유사도 계산\n",
        "def similarity(doc1, doc2):\n",
        "  cnt = 0\n",
        "  for token in doc1:\n",
        "    if token in doc2:\n",
        "      cnt = cnt+1\n",
        "  return cnt/len(doc1)\n",
        "\n",
        "#문장 정의\n",
        "sentence1 = \"6월에 뉴턴은 선생님의 제안으로 트리니티에 입학했다.\"\n",
        "sentence2 = \"6월에 뉴턴은 선생님의 제안으로 대학교에 입학했다.\"\n",
        "sentence3 = \"나는 맛있는 밥을 뉴턴 선생님과 함께 먹었다.\"\n",
        "\n",
        "# 형태소 분석기에서 명사(단어) 추출\n",
        "komoran = Komoran()\n",
        "bow1 = komoran.nouns(sentence1)\n",
        "bow2 = komoran.nouns(sentence2)\n",
        "bow3 = komoran.nouns(sentence3)\n",
        "\n",
        "# 단어 n-gram 토큰 추출 \n",
        "doc1 = word_ngram(bow1,2)  # 2-gram 방식으로 추출\n",
        "doc2 = word_ngram(bow2,2)\n",
        "doc3 = word_ngram(bow3,2)\n",
        "\n",
        "# 추출된 n-gram 토큰 출력\n",
        "print(doc1)\n",
        "print(doc2)\n",
        "\n",
        "# 유사도 계산\n",
        "r1 = similarity(doc1, doc2)\n",
        "r2 = similarity(doc3, doc1)\n",
        "\n",
        "# 계산된 유사도 출력\n",
        "print(r1)\n",
        "print(r2)\n"
      ],
      "metadata": {
        "id": "L0D-v4DhCBWl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b763385-cbc4-4e84-8b83-b11693c1e501"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: KoNLPy in /usr/local/lib/python3.7/dist-packages (0.6.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from KoNLPy) (1.4.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from KoNLPy) (4.9.1)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from KoNLPy) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->KoNLPy) (4.1.1)\n",
            "(('6월', '뉴턴'), ('뉴턴', '선생님'), ('선생님', '제안'), ('제안', '트리니티'), ('트리니티', '입학'), ('입학',))\n",
            "(('6월', '뉴턴'), ('뉴턴', '선생님'), ('선생님', '제안'), ('제안', '대학교'), ('대학교', '입학'), ('입학',))\n",
            "0.6666666666666666\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# n-gram 은 전체 문장을 고려한 언어 모델보다 정확도가 떨어질 수 있습니다. \n",
        "# n을 크게 잡을수록 비교 문장의 토큰과 비교할 때 카운트를 놓칠 확률이 커집니다.\n",
        "# n을 작게 잡을수록 카운트 확률은 높아지지만 문맥을 파악하는 정확도는 떨어질 수밖에 없는 구조이므로 n의 설정은 매우 중요합니다. 보통 1~5사이의 값을 많이 사용합니다.\n",
        "\n",
        "# 음절단위의 n-gram 모델도 존재하며, 두 모델의 결과는 학습 말뭉치 종류와 그 양에 따라 성능이 크게 차이 납니다. \n",
        "# 일반적으로 학습 데이터가 작을 땐 음절 단위의 모델이 유리하지만 문맥을 파악하는 정확도는 떨어질 수밖에 없는 단점이 존재합니다.\n"
      ],
      "metadata": {
        "id": "vTVdBZInbS5s"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#코사인 유사도\n",
        "\n",
        "# 벡터 간 거리나 각도를 이용해 유사성을 파악할 수 있습니다. 이책에서는 코사인 유사도를 설명하겠습니다.\n",
        "# 코사인 유사도는 벡터의 크기와 상관없이 결과가 안정적입니다.(<-> n-gram) 따라서, 코사인 유사도는 다양한 차원에서 적용 가능해 실무에서 많이 사용합니다.\n",
        "\n",
        "#similarity = cos(theta)\n",
        "# 두 벡터의 방향이 같아질 수록 유사하다 볼 수 있습니다. \n",
        "#분자는 두 벡터의 내적을 의미합니다.\n",
        "#분모는 두 벡터의 크기의 곱을 의미합니다.\n"
      ],
      "metadata": {
        "id": "AF9VJh-5b_ra"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 코사인 유사도 계산\n",
        "\n",
        "from konlpy.tag import Komoran\n",
        "import numpy as np\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "#코사인 유사도 계산\n",
        "def cos_sim(vec1, vec2):\n",
        "  return dot(vec1, vec2) / (norm(vec1) * norm (vec2))  #numpy의 dot, norm(유클리드 norm을 주로 사용함)\n",
        "\n",
        "#TDM 만들기\n",
        "def make_term_doc_mat(sentence_bow, word_dics):\n",
        "  freq_mat = {}\n",
        "\n",
        "  for word in word_dics: \n",
        "    freq_mat[word] = 0 \n",
        "\n",
        "  for word in word_dics:\n",
        "    if word in sentence_bow:\n",
        "      freq_mat[word] += 1\n",
        "  \n",
        "  return freq_mat\n",
        "\n",
        "\n",
        "# 단어 벡터 만들기\n",
        "def make_vector(tdm):\n",
        "  vec = []\n",
        "  for key in tdm:\n",
        "    vec.append(tdm[key])\n",
        "  return vec\n",
        "\n",
        "# 문장 정의\n",
        "sentence1 = \"6월에 뉴턴은 선생님의 제안으로 트리니티에 입학했다.\"\n",
        "sentence2 = \"6월에 뉴턴은 선생님의 제안으로 대학교에 입학했다.\"\n",
        "sentence3 = \"나는 맛있는 밥을 뉴턴 선생님과 함께 먹었다.\"\n",
        "\n",
        "#형태소 분석기를 이용해 단어 묶음 리스트 생성\n",
        "komoran = Komoran()\n",
        "bow1 = komoran.nouns(sentence1)\n",
        "bow2 = komoran.nouns(sentence2)\n",
        "bow3 = komoran.nouns(sentence3)\n",
        "\n",
        "#단어 묶음 리스트를 하나로 합침\n",
        "bow = bow1 + bow2 + bow3\n",
        "\n",
        "#단어 묶음에서 중복을 제거해 단어 사전 구축\n",
        "word_dics=[]\n",
        "for token in bow:\n",
        "  if token not in word_dics:\n",
        "    word_dics.append(token)\n",
        "\n",
        "#문장별 단어 문서 행렬 계산\n",
        "freq_list1 = make_term_doc_mat(bow1, word_dics)\n",
        "freq_list2 = make_term_doc_mat(bow2, word_dics)\n",
        "freq_list3 = make_term_doc_mat(bow3, word_dics)\n",
        "print(freq_list1)\n",
        "print(freq_list2)\n",
        "print(freq_list3)\n",
        "\n",
        "# 문장 벡터 생성\n",
        "doc1 = np.array(make_vector(freq_list1))     # 코사인 유사도 함수의 인자는 반드시 넘파이 배열로 넘겨야함.\n",
        "doc2 = np.array(make_vector(freq_list2))\n",
        "doc3 = np.array(make_vector(freq_list3))\n",
        "\n",
        "# 코사인 유사도 계산\n",
        "r1 = cos_sim(doc1, doc2)\n",
        "r2 = cos_sim(doc3, doc1)\n",
        "print(r1)\n",
        "print(r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0-qUW4-LvSJ",
        "outputId": "7a0d047d-0cf5-4b7a-d057-7fa1bb0d2dba"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'6월': 1, '뉴턴': 1, '선생님': 1, '제안': 1, '트리니티': 1, '입학': 1, '대학교': 0, '밥': 0, '선생': 0, '님과 함께': 0}\n",
            "{'6월': 1, '뉴턴': 1, '선생님': 1, '제안': 1, '트리니티': 0, '입학': 1, '대학교': 1, '밥': 0, '선생': 0, '님과 함께': 0}\n",
            "{'6월': 0, '뉴턴': 1, '선생님': 0, '제안': 0, '트리니티': 0, '입학': 0, '대학교': 0, '밥': 1, '선생': 1, '님과 함께': 1}\n",
            "0.8333333333333335\n",
            "0.20412414523193154\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 의미상 연관성은 없었지만 '뉴턴'과 '선생님'이라는 단어가 문장1과 문장3에 포함되어 있기 때문에 작게나마 유사도가 측정되었습니다. \n",
        "# 따라서, 코사인 유사도가 n-gram 유사도에 비해 성능상 이점이 많은 것을 확인할 수 있습니다.\n",
        "\n",
        "# + Word2Vec 라이브러리에 유사도를 계산하는 함수들을 제공하므로 직접 예제로 구현하는 내용은 담지 않았습니다.\n"
      ],
      "metadata": {
        "id": "6LO70o7bc6Pp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CHAPTER 6 챗봇 엔진에 필요한 딥러닝 모델"
      ],
      "metadata": {
        "id": "ma0dHvmkO-hC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6.1 빠르게 케라스 정리하기\n"
      ],
      "metadata": {
        "id": "1zwuFOArPC7u"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cfVAMAk2fYpw"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}